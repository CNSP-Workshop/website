<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>Resources | CNSP2022</title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<meta name="keywords" content="Your keywords">
<meta name="author" content="Your name">
<link rel="stylesheet" href="styles.css" />
</head>
<body id="page2">
<div class="bg-main">
  <!--==============================header=================================-->
 <div class="header_bg">
  <div class="header">

      <div class="main">
        <h1><a href="#"><img src="images/CNSP_Logo.gif" alt="" style="height:150px;"></a></h1>

	  </div>

        <nav>
          <ul class="sf-menu">
            <li><a href="index.html">Home </a></li>
            <li><a href="registration.html">Registration </a></li>
            <li><a href="schedule.html">Schedule </a></li>
            <li class="current"><a href="resources.html">Resources </a></li> <!-- Table with datasets + conversion code + preprocessing code. -->
            <!--<li class="last"><a href="other.html">Other activities </a></li>-->
          </ul>
        </nav>
  </div><div class="clear"></div>
  </div>
  <div class="border-top"></div>

  <!--==============================content====================================-->
  <section id="content">
    <div class="container_12">
      <div class="wrapper border-vert-resouorces">
        <article class="grid_12">
          <h2>Resources</h2>
		<p>A list of resources that we will use during the workshop. The password to download datasets and scripts can be found <a href="https://www.data.cnspworkshop.net/CNSP2021_booklet.pdf">here</a>		  
		Note that each dataset should be used according to its own license and should be referenced as indicated by the authors in their original submission.<br/>
		If you experience any issue when downloading the data, consider trying from a different browser.<br/>
		For the workshop attendees: The main files to download are <a href="https://www.data.cnspworkshop.net/data/CNSP-workshop2021_code.zip">Workshop basic</a> and the CND version of <a href="https://cnspworkshop.net/data/datasetCND_LalorNatSpeech.zip">Natural speech listening</a> below</p>

		<p style="text-align:justify"><br/>
		<h5>Continuous-event Neural Data data format</h5>
		<a href="cndFormat.html">Please check out our CND data format (Continuous-event Neural Data)</a> for data sharing and standardisation. 
		Detailed insights on the format can be found in our <a href="https://docs.google.com/document/d/13VUyj1rHGnye-HyO9Goaxkd3qal-hBjh49mFfWq_DNM/edit">data-preparation guidelines 2021</a>. The data-preparation guidelines 2022 will be available shortly.		 
		</p><br/>

		<p style="text-align:justify"><br/>
		<h5>CNSP2021 lectures and tutorials</h5>
		Check out the videos of all the sessions of CNSP2021 <a href="https://cnspworkshop.net/videos.html">here</a>.<br/> 
		and the CNSP2021 <a href="https://www.data.cnspworkshop.net/CNSP2021_booklet.pdf">booklet</a> for further information.  
		</p><br/>
		
		  <table>
		  	  
	          <tr><td><b><u>CNSP2022 Tutorials</u></b></td></tr>	
		  <tr>
			<td><b>Link</b></td>
			<td><b>Authors</b></td>
			<td><b>Paper</b></td>
			<td><b>Description</b></td>
		  </tr>
			  
		  <tr>
			<td><b>-</b></td>
			<td><b>-</b></td>
			<td><b>-</b></td>
			<td><b>-</b></td>
		  </tr>
		  
                  <tr><td><b></b></td><td><b></b></td><td><b></b></td><td><b></b></td></tr>
		  <tr><td><b></b></td><td><b></b></td><td><b></b></td><td><b></b></td></tr>
		  <tr><td><b></b></td><td><b></b></td><td><b></b></td><td><b></b></td></tr>
		  
		  <tr><td><b><u>CNSP2021 Tutorials</u></b></td></tr>	
		  <tr>
			<td><b>Link</b></td>
			<td><b>Authors</b></td>
			<td><b>Paper</b></td>
			<td><b>Description</b></td>
		  </tr>
			  
		  <tr>
		      <td><a href="https://www.data.cnspworkshop.net/data/Gwilliams_tutorial.zip">Laura Gwilliams's tutorial</a></td>
		      <td>Laura Gwilliams</td>
		      <td><a href="https://elifesciences.org/articles/56603">Gwilliams & King (2020)</a></td>
		      <td>Demonstration of sci-kit learn for neural decoding</td>
		  </tr>
		  <tr>
			<td><a href="https://www.data.cnspworkshop.net/data/CNSP-workshop2021_code.zip">Workshop basic</a></td>
			<td>Di Liberto</td>
			<td>See <a href="https://docs.google.com/document/d/13VUyj1rHGnye-HyO9Goaxkd3qal-hBjh49mFfWq_DNM/edit">data-preparation guidelines 2021</a></td>
			<td>Workshop basic scripts, libraries, and folder structure.</td>
		  </tr>
		  <tr>
			<td><a href="https://www.data.cnspworkshop.net/data/encoding_tutorial_CNSP2021.zip">Encoding tutorial</a><br/>
			    <a href="https://www.data.cnspworkshop.net/data/CNSP-tutorial2.zip">Decoding tutorial</a><br/>
			    <a href="https://www.data.cnspworkshop.net/data/CNSP-tutorial3.zip">Multivariate tutorial</a><br/>
			    <a href="https://www.data.cnspworkshop.net/data/cuttingEEG2021-TRFtutorial.zip">TRF tutorial</a></td>
			<td>Zuk<br/>Crosse<br/>Nidiffer<br/>Lalor & Crosse</td>
			<td></td>
			<td>Workshop tutorial scripts (encoding, decoding, and multivariate modelling tutorials).</td>
		  </tr>




		  <tr>
			<td><b></b></td>
			<td><b></b></td>
			<td><b></b></td>
			<td><b></b></td>
		  </tr>
		  <tr><td><b><u>Datasets</u></b></td></tr>

		  <tr>
			<td><b>Original Link</b></td>
			<td><b>Authors</b></td>
			<td><b>Paper</b></td>
			<td><b>CND data structure</b></td>
		  </tr>
		  <tr>
			<td><a href="https://doi.org/10.5061/dryad.070jc">Speech - multiple EEG datasets</a></td>
			<td>Broderick, Andreson, Di Liberto, Crosse and Lalor</td>
			<td><a href="https://doi.org/10.1016/j.cub.2018.01.080">Current Biology, 2018</a></td>
			<td><a href="https://www.data.cnspworkshop.net/data/datasetCND_LalorNatSpeech.zip">Download (natural speech listening)</a><br/>
			    <a href="https://www.data.cnspworkshop.net/data/datasetCND_LalorNatSpeechReverse.zip">Download (reverse speech listening)</a><br/>
			    <a href="https://www.data.cnspworkshop.net/data/LalorCocktailParty.zip">Download (cocktail party dataset)</a></td>
		  </tr>
		  <tr>
			<td><a href="https://datadryad.org/stash/dataset/doi:10.5061/dryad.g1jwstqmh">Bach piano melodies - EEG dataset</a></td>
			<td>Di Liberto, Pelofi, Bianco, Patel, Mehta, Herrero, de Cheveigné, Shamma and Mesgarani</td>
			<td><a href="https://elifesciences.org/articles/51784">eLife, 2020</a></td>
			<td><a href="https://www.data.cnspworkshop.net/data/datasetCND_diliBach.zip">Download</a></td>
		  </tr>
		  <tr>
			<td><a href="https://doi.org/10.5061/dryad.dbrv15f0j">Music listening/imagery - EEG dataset</a></td>
			<td>Marion, Di Liberto, and Shamma</td>
			<td><a href="https://t.co/h0hyH4JRAt?amp=1">Paper 1</a>; <a href="https://t.co/njKaG7sBlW?amp=1">Paper 2</a></td>
			<td><a href="https://www.data.cnspworkshop.net/data/datasetCND_musicImagery.zip">Download CND</a></td>
		  </tr>
	 	  <tr>
			<td><a href="https://deepblue.lib.umich.edu/data/concern/data_sets/bg257f92t">Speech listening - EEG dataset</a></td>
			<td>Brennan and Hale </td>
			<td><a href="https://doi.org/10.1371/journal.pone.0207741">PLoS ONE, 2019</a></td>
			<td>Available after CNSP2021</td>
		  </tr>
		  <tr>
			<td><a href="https://doi.org/10.5061/dryad.070jc">Preprocessed Speech EEG dataset</a></td>
			<td>Broderick, Andreson, Di Liberto, Crosse and Lalor</td>
			<td><a href="https://doi.org/10.1016/j.cub.2018.01.080">Current Biology, 2018</a></td>
			<td><a href="https://www.data.cnspworkshop.net/data/dataSub10_proc.mat">Download CND</a></td>
		  </tr>	  
		  <!--<tr>
			<td>Dataset</td>
			<td>Authors</td>
			<td>Paper</td>
			<td>Conversion script</td>
		  </tr>
		  <tr>
			<td>Dataset</td>
			<td>Authors</td>
			<td>Paper</td>
			<td>Conversion script</td>
		  </tr>
		  <tr>
			<td>Dataset</td>
			<td>Authors</td>
			<td>Paper</td>
			<td>Conversion script</td>
		  </tr>-->

		  <tr>
			<td><b></b></td>
			<td><b></b></td>
			<td><b></b></td>
			<td><b></b></td>
		  </tr>
		  <tr><td><b> </b></td><td><b></b></td><td><b></b></td><td><b></b></td></tr>
		  <tr><td><b> </b></td><td><b></b></td><td><b></b></td><td><b></b></td></tr>
		  <tr><td><b> </b></td><td><b></b></td><td><b></b></td><td><b></b></td></tr>
		
			  
		  <tr><td><b><u>Toolboxes</u></b></td></tr>

		  <tr>
			<td><b>Link</b></td>
			<td><b>Authors</b></td>
			<td><b>Paper</b></td>
			<td><b>Description</b></td>
		  </tr>
		  <tr>
			<td><a href="https://github.com/mickcrosse/mTRF-Toolbox">mTRF-Toolbox (CNSP domain-specific)</a></td>
			<td>Crosse, Di Liberto, Bednar and Lalor</td>
			<td><a href="https://www.frontiersin.org/articles/10.3389/fnhum.2016.00604/full">Front Hum Neurosci 2016</a></td>
			<td>A MATLAB toolbox for relating neural signals to continuous stimuli.</td>
		  </tr>
		  <tr>
			<td><a href="https://eelbrain.readthedocs.io/">Eelbrain (CNSP domain-specific)</a></td>
			<td>Brodbeck, Das, Kulasingham</td>
			<td><a href="https://www.biorxiv.org/content/10.1101/2021.08.01.454687v1">Paper</a><br/><a href="https://www.data.cnspworkshop.net/CNSP2021_slides/CNSP2021_ChristianBrodbeckSlides.pdf">CNSP2021 slides</a></td>
			<td>A Python toolbox for relating neural signals to continuous stimuli.</td>
		  </tr>
	          <tr>
			<td><a href="http://audition.ens.fr/adc/NoiseTools/">NoiseTools</a></td>
			<td>Alain de Cheveigné</td>
			<td>Multiple references. See <a href="http://audition.ens.fr/adc/NoiseTools/">here</a></td>
			<td>a Matlab toolbox to denoise and analyze multichannel electrophysiological data, such as from EEG, MEG, electrode arrays, optical imaging, or fMRI.</td>
		  </tr>
	          <tr>
			<td><a href="https://sccn.ucsd.edu/eeglab/index.php">EEGLAB<br/>(General purpose)</a></td>
			<td>Delorme and Makeig, J. Neurosci Methods, 2004</td>
			<td><a href="https://www.sciencedirect.com/science/article/pii/S0165027003003479">Paper</a></td>
			<td>EEGLAB is an interactive Matlab toolbox for processing continuous and event-related EEG, MEG and other electrophysiological data.</td>
		  </tr>
		  <tr>
			<td><a href="https://mne.tools/stable/index.html">MNE<br/>(General purpose)</a></td>
			<td>Gramfort et al. 2013</td>
			<td><a href="https://doi.org/10.3389/fnins.2013.00267">Paper</a></td>
			<td>Open-source Python package for exploring, visualizing, and analyzing human neurophysiological data: MEG, EEG, sEEG, ECoG, NIRS, and more.</td>
		  </tr>	  
			  
			  
		  <tr><td><b></b></td><td><b></b></td><td><b></b></td><td><b></b></td></tr>
		  <tr><td><b></b></td><td><b></b></td><td><b></b></td><td><b></b></td></tr>
		  <tr><td><b></b></td><td><b></b></td><td><b></b></td><td><b></b></td></tr>
			  
			  
		  <tr><td><b><u>Other Useful References</u></b></td></tr>

		  <tr>
			<td><b>Link</b></td>
			<td><b>Authors</b></td>
			<td><b>Description</b></td>
			<td><b>Year</b></td>
		  </tr>
		  <!--<tr>
			<td><a href="https://www.frontiersin.org/articles/10.3389/fnhum.2016.00604/full">Paper</a></td>
			<td>Crosse, Di Liberto, Bednar, Lalor</td>
			<td>"The multivariate temporal response function (mTRF) toolbox: a MATLAB toolbox for relating neural signals to continuous stimuli", <i>Frontiers in Human Neuroscience</i></td>
			<td>2016</td>
		  </tr>-->
		  <tr>
			<td><a href="https://doi.org/10.3389/fnins.2021.705621">Paper</a></td>
			<td>Crosse, Zuk, Di Liberto, Nidiffer, Molholm, Lalor</td>
			<td>Using TRFs in applied research. "Linear Modeling of Neurophysiological Responses to Naturalistic Stimuli: Methodological Considerations for Applied Research", <i>Frontiers in Neuroscience</i></td>
			<td>2021</td>
		  </tr>
		  <!--<tr>
		      <td><a href="">Paper</a></td>
		      <td>Nunez-Elizalde, Huth, Gallant</td>
		      <td>"Voxelwise encoding models with non-spherical multivariate normal priors", <i>Neuroimage</i></td>
		      <td>2019</td>
		  </tr>-->
		  <tr>
			<td><a href="https://www.sciencedirect.com/science/article/pii/S1053811920310715">Paper</a></td>
			<td>Di Liberto, Nie, Yeaton, Khalighinejad, Shamma, Mesgarani</td>
			<td>This study used multivariate encoding TRFs. "Neural representation of linguistic feature hierarchy reflects second-language proficiency", <i>Neuroimage</i></td>
			<td>2021</td>
		  </tr>
		  <!--<tr>
			<td><a href="https://elifesciences.org/articles/51784">Paper</a></td>
			<td>Di Liberto, Pelofi, Bianco, Patel, Mehta, Herrero, de Cheveigne, Shamma, Mesgarani</td>
			<td>TRFs with music stimuli (EEG and ECoG). "Cortical encoding of melodic expectations in human temporal cortex", <i>eLife</i></td>
			<td>2020</td>
		  </tr>	-->
		  <tr>
			<td><a href="https://computationalaudiology.com/resources/">Computational Audiology Resources</a></td>
			<td>
Barbour, Hohmann, Ntlhakana, Zeng, Buhl, Goehring, Warzybok, Wasmann</td>
			<td>This initiative strives to highlight recent examples that illustrate the potential of a computational approach to audiology. computationalaudiology.com aims to become a central hub for sharing resources that are useful for researchers and clinicians.</td>
			<td>2020-current</td>
		  </tr>		  

		</table>


        </article>


      </div>
    </div>
  </section>
</div>
<!--==============================footer================================-->
<!-- particles.js container -->
  <footer>

  <hr WIDTH="58.5%" ALIGN="LEFT">
  <hr WIDTH="58.5%" ALIGN="RIGHT">
  <div class="container_12">


    <div class="wrapper">
      <article class="grid_8">
          <u>Organisers</u><br/>
		  Giovanni Di Liberto, PhD<br/>
		  Nathaniel Zuk, PhD<br/>
		  Mick Crosse, PhD<br/>
		  Aaron Nidiffer, PhD<br/>
		  Giorgia Cantisani, PhD<br/>
		  Stephanie Haro<br/>
          CNSPWorkshop /at/ gmail /dot/ com
      </article>
      <article class="grid_4">
        <div>
			<a href="https://github.com/CNSP-Workshop"><font color="BBBBBB">GitHub</font></a><br/>
			<a href="https://twitter.com/CnspWorkshop"><font color="BBBBBB">Twitter</font></a><br/>
			<br/>
		</div>
		<div class="privacy">2021 &nbsp;All rights reserved <br />
          <!-- Do not remove -->Website by <a href="https://diliberg.net" title="Giovanni Di Liberto">Giovanni Di Liberto</a><!-- end --></div>
		  <!-- Do not remove -->Original design by <a href="http://www.libdesigner.com/2012/08/24/free-animal-skin-and-fur-textures-for-your-projects/" title="Animal Fur Textures">Animal Fur Textures</a><!-- end --><br/>
      </article>
    </div>
  </div>
</footer>
</div>
</body>
</html>
