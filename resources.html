<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>CNSP Resources</title>
<meta name="keywords" content="Cognitive, Natural, Sensory Processing, EEG, Neural, Speech, Music, Perception, Machine Learning" />
<meta name="description" content="" />
<meta name="author" content="Giovanni M. Di Liberto">
<link rel="stylesheet" href="styles.css" />
</head>
<body id="page2">
<div class="bg-main">

<!--==============================header=================================-->
  <div class="header_bg">
    <div class="header">

      <div class="main">
        <h1><a href="#"><img src="images/CNSP_Logo.gif" alt="" style="height:150px;"></a></h1>
      </div>

      <nav>
        <ul class="sf-menu">
          <li><a href="index.html">Home </a></li>
          <li><a href="about.html">About </a></li>
          <li><a href="cndFormat.html">CND </a></li>
          <li class="current"><a href="resources.html">Resources </a></li>
          <li><a href="research.html">Research </a></li>
          <li><a href="workshops.html">Workshops </a></li>
          <li><a href="hackathon.html">Hackathon </a></li>
          <li class="last"><a href="registration.html">Registration </a></li> 
        </ul>
      </nav>
    </div>
    <div class="clear">
    </div>
  </div>

  <div class="border-top"></div>
  <!--<hr WIDTH="58.5%" ALIGN="LEFT">-->
  <!--<hr WIDTH="58.5%" ALIGN="RIGHT">-->
  <!--<hr WIDTH="65%" ALIGN="CENTER">-->

<!--==============================content====================================-->
<section id="content">
	<div class="container_12">
		<div class="wrapper border-vert-resouorces">
			<article class="grid_12">
				<h2>Resources</h2>
				<p>These resources include original and publicly available datasets that were standardised according to the CND data structure, as well as original analysis scripts and links to publicly available toolboxes for the analysis of continuous-event neural data. 

				Note that each dataset should be used according to its own license and should be referenced as indicated by the authors in their original submission.
			</p>

				<p style="text-align:justify"><h5>Continuous-event Neural Data data format</h5>
					<a href="cndFormat.html">Please check out the CND specifications (Continuous-event Neural Data)</a> and the <a href="https://cnsp-resources.readthedocs.io">documentation website</a>. You can also refer to this <a href="https://arxiv.org/abs/2309.07671">paper</a> for more detailed insights. 

					Detailed insights on the format can be found in our <a href="https://docs.google.com/document/d/1z1iYe9dhOnKBZFLVGH5YnabEtODLzzA2PHIObCu8Mlg">Resource preparation guidelines</a> and on the <a href="https://docs.google.com/document/d/1llE0v-e2pdCv5WXoIZzU2V00T2TCElviH7Vu2C8RS50">BYOData Preparation Guidelines</a>.
				</p><br/>

<table>
<!--==============================DATASETS=================================-->
<tr><th><b>Datasets</b></th> <th></th> <th></th> <th></th> </tr>

<tr>
	<td><b>Authors</b></td>
	<td><b>Original Link</b></td>
	<td><b>Paper</b></td>
	<td><b>Download CND data</b></td>
</tr>

<tr>
	<td>Broderick, Andreson, Di Liberto, Crosse and Lalor</td>
	<td><a href="https://doi.org/10.5061/dryad.070jc">EEG: Natural, reverse & cocktail party speech listening, English</a></td>
	<td><a href="https://doi.org/10.1016/j.cub.2018.01.080"><i>Current Biology</i>, 2018</a></td>
	<td><a href="https://www.data.cnspworkshop.net/data/datasetCND_LalorNatSpeech.zip">Download natural speech dataset</a> <a href="https://www.data.cnspworkshop.net/data/CNSP2022_intermediate/LalorNatSpeech/dataStim.mat">***</a><br/>
		<a href="https://www.data.cnspworkshop.net/data/datasetCND_LalorNatSpeechReverse.zip">Download reverse speech dataset</a><br/>
		<a href="https://www.data.cnspworkshop.net/data/datasetCND_LalorCocktailParty.zip">Download cocktail party dataset</a></td>
</tr>

<tr>
	<td>Di Liberto, Pelofi, Bianco, Patel, Mehta, Herrero, de Cheveign√©, Shamma and Mesgarani</td>
	<td><a href="https://datadryad.org/stash/dataset/doi:10.5061/dryad.g1jwstqmh">EEG: Bach piano melodies</a></td>
	<td><a href="https://doi.org/10.7554/eLife.51784"><i>eLife</i>, 2020</a></td>
	<td><a href="https://www.data.cnspworkshop.net/data/datasetCND_diliBach.zip">Download diliBach dataset</a></td>
</tr>

<tr>
	<td>Marion, Di Liberto, and Shamma</td>
	<td><a href="https://doi.org/10.5061/dryad.dbrv15f0j">EEG: Music listening & imagery</a></td>
	<td><a href="https://doi.org/10.1523/JNEUROSCI.0183-21.2021"><i>J Neurosci</i>, 2021 (Part I)</a><br/>
	<a href="https://doi.org/10.1523/JNEUROSCI.0184-21.2021"><i>J Neurosci</i>, 2021 (Part II)</a></td>
	<td><a href="https://www.data.cnspworkshop.net/data/datasetCND_musicImagery.zip">Download Music Imagery dataset</a></td>
</tr>

<tr>
	<td>Brennan and Hale </td>
	<td><a href="https://deepblue.lib.umich.edu/data/concern/data_sets/bg257f92t">EEG: Natural speech</a></td>
	<td><a href="https://doi.org/10.1371/journal.pone.0207741"><i>PLoS ONE</i>, 2019</a></td>
	<td><a href="https://www.data.cnspworkshop.net/data/AliceSpeech.zip">Download dataset</td>
</tr>

<tr>
	<td>Das, Francart, Bertrand</td>
	<td><a href="https://zenodo.org/record/3997352#.X0fP1sgza5g">EEG: Cocktail party speech</a></td>
	<td><a href="https://doi.org/10.1088/1741-2560/13/5/056014"><i>J Neural Eng</i>, 2016</a></td>
	<td><a href="https://www.data.cnspworkshop.net/data/AAD_KULeuven.zip">Download dataset</a></td>
</tr>

<tr>
	<td>Di Liberto, Attaheri, Goswami, et al.</td>
	<td><a href="https://osf.io/mdnwg/">EEG: Baby rhythm speech</a></td>
	<td><a href="https://www.nature.com/articles/s41467-023-43490-x"><i>Nature Communications</i>, 2023</a></td>
	<td><a href="https://osf.io/mdnwg/">Download BabyRhythm dataset</a></td>
</tr>

<tr>
	<td>Yahav, Rabinovitch, Korisky, Harel, Bliechner and Zion Golumbic</td>
	<td><a href="https://osf.io/bzean/">EEG: Video lectures with distracting speech </a></td>
	<td><a href="https://doi.org/10.1101/2023.12.27.573349"><i>bioRxiv</i>, 2025</a></td>
	<td><a href="https://osf.io/bzean/">Download dataset</a></td>
</tr>

<tr>
	<td>Levy, Zvilichovsky,  Korisky, Bidet-Caulet, Schweitzer, Zion Golumbic</td>
	<td><a href="https://osf.io/svjqg/">Selective attention and sensitivity to auditory disturbances in a virtually real Classroom </a></td>
	<td><a href="https://elifesciences.org/reviewed-preprints/103235"><i>eLife</i>, 2025</a></td>
	<td><a href="https://osf.io/svjqg/">Download dataset</a></td>
</tr>
	
<tr>
	<td>Rogachev and Sysoeva</td>
	<td><a href="https://osf.io/c3agw/">EEG: Child stories</a></td>
	<td><a href="https://doi.org/10.1016/j.cogsys.2024.101236"><i>Cognitive Systems Approach</i>, 2024</a></td>
	<td><a href="https://osf.io/c3agw/">Download dataset</a></td>
</tr>

	
<tr>
	<td>Accou, Bollens, Gillis, Verheijen, Van hamme, Francart</td>
	<td><a href="https://rdr.kuleuven.be/dataset.xhtml?persistentId=doi:10.48804/K3VSND">EEG: Speech listening, Flemish, N=85</a></td>
	<td><a href="https://www.mdpi.com/2306-5729/9/8/94"><i>Data</i>, 2024</a></td>
	<td><a href="https://www.data.cnspworkshop.net/data/SparrKULee1.zip">Download SparrKULee data-lite 1</a><br/>
		<a href="https://www.data.cnspworkshop.net/data/SparrKULee2.zip">Download SparrKULee data-lite 2</a><br/>
		<a href="https://www.data.cnspworkshop.net/data/SparrKULee_README.txt">SparrKULee README</a></td>
</tr>


	


		  <!--<tr>
			<td>Broderick, Andreson, Di Liberto, Crosse and Lalor</td>
			<td><a href="https://doi.org/10.5061/dryad.070jc">Preprocessed Speech EEG dataset</a></td>
			<td><a href="https://doi.org/10.1016/j.cub.2018.01.080">Current Biology, 2018</a></td>
			<td><a href="https://www.data.cnspworkshop.net/data/dataSub10_proc.mat">Download CND</a></td>
		  </tr>	  
		  <tr>
			<td>Dataset</td>
			<td>Authors</td>
			<td>Paper</td>
			<td>Conversion script</td>
		  </tr>
		  <tr>
			<td>Dataset</td>
			<td>Authors</td>
			<td>Paper</td>
			<td>Conversion script</td>
		  </tr>
		  <tr>
			<td>Dataset</td>
			<td>Authors</td>
			<td>Paper</td>
			<td>Conversion script</td>
		  </tr>-->

<!--==============================TOOLBOXES=================================-->
<tr><th><b>Toolboxes</b></th> <th></th> <th></th> <th></th> </tr>

<tr>
	<td><b>Link</b></td>
	<td><b>Authors</b></td>
	<td><b>Paper</b></td>
	<td><b>Description</b></td>
</tr>

<tr>
	<td>CNSP Resources <a href="https://github.com/CNSP-Workshop/CNSP-resources">GitHub</a> and <a href="https://cnsp-resources.readthedocs.io/">documentation</a><br/></td>
	<td>Di Liberto, Nidiffer, Crosse, Zuk, Haro, Cantisani et al.</td>
	<td><a href="https://arxiv.org/abs/2309.07671"><i>arXiv</i>, 2023</a></td>
	<td>The CNSP analytic resources and guidelines for relating neural signals to continuous stimuli.</td>
</tr>

<tr>
	<td><a href="https://data.cnspworkshop.net/data/DataBrowserInstaller.zip">CNSP Data Browser (beta)<br/></a></td>
	<td>Di Liberto et al.</td>
	<td><a href="https://arxiv.org/abs/2309.07671"><i>arXiv</i>, 2023</a></td>
	<td>An interactive MATLAB toolbox for data preprocessing, TRF and cross-correlation analyses, feature design, CND import/export, and data simulation.</td>
</tr>

<tr>
	<td><a href="https://github.com/mickcrosse/mTRF-Toolbox">mTRF-Toolbox<br/>(Domain-specific)</a></td>
	<td>Crosse, Di Liberto, Bednar & Lalor</td>
	<td><a href="https://www.frontiersin.org/articles/10.3389/fnhum.2016.00604/full"><i>Front Hum Neurosci</i>, 2016</a></td>
	<td>A MATLAB toolbox for relating neural signals to continuous stimuli.</td>
</tr>

<tr>
	<td><a href="https://eelbrain.readthedocs.io/">Eelbrain<br/>(Domain-specific)</a></td>
	<td>Brodbeck et al.</td>
	<td><a href="https://doi.org/10.7554/eLife.85012"><i>eLife</i>, 2023</a><br/>
		<a href="https://www.data.cnspworkshop.net/CNSP2021_slides/CNSP2021_ChristianBrodbeckSlides.pdf">CNSP2021 slides</a></td>
		<td>A Python toolbox for relating neural signals to continuous stimuli.</td>
</tr>

<tr>
	<td><a href="http://audition.ens.fr/adc/NoiseTools/">NoiseTools</a></td>
	<td>de Cheveign√© et al.</td>
	<td><a href="http://audition.ens.fr/adc/NoiseTools/">Papers</a></td>
	<td>A MATLAB toolbox for denoising and analysing continuous and event-related neural data.</td>
</tr>

<tr>
	<td><a href="https://sccn.ucsd.edu/eeglab/index.php">EEGLAB<br/>(General purpose)</a></td>
	<td>Delorme & Makeig</td>
	<td><a href="https://doi.org/10.1016/j.jneumeth.2003.10.009"><i>J Neurosci Methods</i>, 2004</a></td>
	<td>An interactive MATLAB toolbox for processing continuous and event-related neural data.</td>
</tr>

<tr>
	<td><a href="https://mne.tools/stable/index.html">MNE<br/>(General purpose)</a></td>
	<td>Gramfort et al.</td>
	<td><a href="https://doi.org/10.3389/fnins.2013.00267"><i>Front Neurosci</i>, 2013</a></td>
	<td>A Python package for exploring, visualizing, and analyzing neural data.</td>
</tr>

<tr>
	<td><a href="https://github.com/mickcrosse/PERMUTOOLS">PERMUTOOLS<br/>(General purpose)</a></td>
	<td>Crosse et al.</td>
	<td><a href="https://doi.org/10.48550/arXiv.2401.09401"><i>arXiv</i>, 2024</a></td>
	<td>A MATLAB package for multivariate permutation testing and effect size measurement.</td>
</tr>

<!--==============================TUTORIALS=================================-->
		  <!-- <tr><th><b><u>CNSP2022 Tutorials</u></b></th> <th></th> <th></th> <th></th> </tr>
		  <tr>
			<td><b>Link</b></td>
			<td><b>Authors</b></td>
			<td><b>Description</b></td>
			<td><b>Relevant tutorial</b></td>
		  </tr>
		  <tr>
			<td><a href="https://www.data.cnspworkshop.net/data/CNSP_resources_skeleton.zip">CNSP Resources Skeleton</a></td>
			<td>CNSP organisers</td>
			<td>Folder structure and a basic example TRF code</td>
			<td>All CNSP tutorials (Day 1)</td>
		  </tr>	
		  <tr>
			<td><a href="https://www.data.cnspworkshop.net/data/CNSP_libs.zip">CNSP Libraries</a></td>
			<td>CNSP organisers</td>
			<td>Unzip them in the 'libs' folder of the skeleton</td>
			<td>All CNSP tutorials (Day 1)</td>
		  </tr>
		  <tr>
			<td><a href="https://www.data.cnspworkshop.net/CNSP2022_videos/resourcePrep.mp4">Video - Resource Preparation</a></td>
			<td>Nidiffer, Di Liberto, and the CNSP2022 participants</td>
			<td>This video will guide you through the CNSP resource preparation (essential practical guidelines from 5min:08s to 16min:08s)</td>
			<td>All CNSP tutorials (Day 1)</td>
		  </tr>
			  
		  <tr>
			  <td><b>Beginner tutorials:</b>
			    <br/><a href="https://www.data.cnspworkshop.net/data/CNSP2022_beginner/TRFtutorial.zip">TRF tutorial</a>
			  </td>
			
			<td>Mick Crosse</td>
			<td>Encoding and decoding models, introduction to multivariate analysis for first-time users. Please unzip in the 'CNSP/tutorials' folder</td>
			<td>Beginner CNSP tutorial (Day 1)</td>
		  </tr>
			  
		  <tr>
			  <td><b>Intermediate tutorials:</b>
			    <br/><a href="https://www.data.cnspworkshop.net/data/CNSP2022_intermediate/IntermediateTutorial_StarterPack.zip">Starter pack</a>
			    <br/><a href="https://www.data.cnspworkshop.net/data/CNSP2022_intermediate/MultivarShuffletutorial.zip">Evaluating multivariate models</a>
			    <br/><a href="https://www.data.cnspworkshop.net/data/CNSP2022_intermediate/BandedRidgeTutorial.zip">Banded ridge regression</a>
			    <br/><a href="https://www.data.cnspworkshop.net/data/CNSP2022_intermediate/CCAtutorial_withoutSolutions.zip">CCA </a>
		                 <a href="https://www.data.cnspworkshop.net/data/CNSP2022_intermediate/CCAtutorial_withSolutions.zip">CCA_solutions</a>
			  </td>
			
			<td>CNSP organisers (Giovanni Di Liberto, Aaron Nidiffer, Nate Zuk)</td>
			<td>Intermediate tutorials. Please unzip in the 'CNSP/tutorials' folder</td>
			<td>Intermediate CNSP tutorials (Day 1)</td>
		  </tr>	  
			  
		  <tr>
			<td><a href="https://www.data.cnspworkshop.net/data/CNSP_2022_tutorial_eelbrain.zip">Eelbrain tutorial (Python)</a></td>
			<td>Joshua Kulasingham</td>
			<td>Demonstrates data preprocessing, forward, and backward modeling with Eelbrain.<br>
				Download the zip file in the link on the left, unzip the file contents, then follow the guide to setup the tutorial: <a href="https://www.data.cnspworkshop.net/data/tutorial_docs/EelbrainTutorial_README.pdf">README</a>.<br>
				For more information, see: <a href="https://ieeexplore.ieee.org/document/9802779">Paper</a> and <a href="https://eelbrain.readthedocs.io/">Eelbrain documentation</a>
			</td>
			<td>TRF Eelbrain tutorial (Day 2)</td>
		  </tr>
		  <tr>
			<td>Envelope decoding using DNNs (Python)</td>
			<td>Mike Thornton</td>
			<td>Compares linear models and deep neural networks (DNN) for envelope decoding from EEG data.<br>
				The tutorial is based in Google Colab. A guide to setup the tutorial can be found in the <a href="https://www.data.cnspworkshop.net/data/tutorial_docs/DNNDecoders_README.pdf">README</a>. <br>
				For more information, see: <a href="https://iopscience.iop.org/article/10.1088/1741-2552/ac7976/meta">Paper</a>
			</td>
			<td>DNN tutorial (Day 2)</td>
		  </tr>
		  <tr>
			<td><b>other tutorials coming soon</b></td>
			<td><b>-</b></td>
			<td><b>-</b></td>
			<td><b>-</b></td>
		  </tr> -->
		  
		  <!--
          <tr><td><b></b></td><td><b></b></td><td><b></b></td><td><b></b></td></tr>
		  <tr><td><b></b></td><td><b></b></td><td><b></b></td><td><b></b></td></tr>
		  <tr><td><b></b></td><td><b></b></td><td><b></b></td><td><b></b></td></tr>
		  <tr><td><b></b></td><td><b></b></td><td><b></b></td><td><b></b></td></tr>
		  -->


<!--==============================OTHER=================================-->
<tr><th><b>Other Useful References</b></th> <th></th> <th></th> <th></th> </tr>

<tr>
	<td><b>Link</b></td>
	<td><b>Authors</b></td>
	<td><b>Description</b></td>
	<td><b>Year</b></td>
</tr>

<!--
		  <tr>
			<td><a href="https://doi.org/10.3389/fnins.2021.705621"><i>Front Neurosci</i> paper</a></td>
			<td>Crosse, Zuk, Di Liberto, Nidiffer, Molholm, Lalor</td>
			<td>Linear Modeling of Neurophysiological Responses to Naturalistic Stimuli: Methodological Considerations for Applied Research.</td>
			<td>2021</td>
		  </tr>-->
		  <!--<tr>
		      <td><a href="">Paper</a></td>
		      <td>Nunez-Elizalde, Huth, Gallant</td>
		      <td>"Voxelwise encoding models with non-spherical multivariate normal priors", <i>NeuroImage</i></td>
		      <td>2019</td>
		  </tr>-->
		  <!--
		  <tr>
			<td><a href="https://doi.org/10.1016/j.neuroimage.2020.117586"><i>NeuroImage</i> paper</a></td>
			<td>Di Liberto, Nie, Yeaton, Khalighinejad, Shamma, Mesgarani</td>
			<td>Neural representation of linguistic feature hierarchy reflects second-language proficiency.</td>
			<td>2021</td>
		  </tr>-->
		  <!--<tr>
			<td><a href="https://elifesciences.org/articles/51784">Paper</a></td>
			<td>Di Liberto, Pelofi, Bianco, Patel, Mehta, Herrero, de Cheveigne, Shamma, Mesgarani</td>
			<td>TRFs with music stimuli (EEG and ECoG). "Cortical encoding of melodic expectations in human temporal cortex", <i>eLife</i></td>
			<td>2020</td>
		  </tr>	-->
		  <!--
		  <tr>
			<td><a href="https://doi.org/10.1109/TBME.2022.3185005"><i>IEEE Trans Biomed Eng</i> paper</a></td>
			<td>Kulasingham, Simon</td>
			<td>Algorithms for estimating time-locked neural response components in cortical processing of continuous speech.</td>
			<td>2022</td>
		  </tr>
		  <tr>
			<td><a href="https://doi.org/10.1088/1741-2552/ac7976"><i>J Neural Eng</i> paper</a></td>
			<td>Thornton, Mandic, Reichenbach</td>
			<td>Robust decoding of the speech envelope from EEG recordings through deep neural networks.</td>
			<td>2022</td>
		  </tr>-->

<tr>
	<td><a href="https://computationalaudiology.com/resources/">Computational audiology resources</a></td>
	<td>Barbour, Hohmann, Ntlhakana, Zeng, Buhl, Goehring, Warzybok, Wasmann</td>
	<td>This initiative strives to highlight recent examples that illustrate the potential of a computational approach to audiology. computationalaudiology.com aims to become a central hub for sharing resources that are useful for researchers and clinicians.</td>
	<td>2020-present</td>
</tr>		  

</table>

        </article>
      </div>
    </div>
  </section>
</div>

<!--==============================footer================================-->
<!-- particles.js container -->
  <footer>

  <hr WIDTH="58.5%" ALIGN="LEFT">
  <hr WIDTH="58.5%" ALIGN="RIGHT">
  <div class="container_12">


    <div class="wrapper">
      <article class="grid_8">
          <u>Organisers</u><br/>
		  Giovanni Di Liberto, PhD<br/>
		  Nathaniel Zuk, PhD<br/>
		  Mick Crosse, PhD<br/>
		  Aaron Nidiffer, PhD<br/>
		  Giorgia Cantisani, PhD<br/>
		  Stephanie Haro<br/>
          CNSPWorkshop /at/ gmail /dot/ com
      </article>
      <article class="grid_4">
        <div>
			<a href="https://github.com/CNSP-Workshop"><font color="BBBBBB">GitHub</font></a><br/>
			<a href="https://twitter.com/CnspWorkshop"><font color="BBBBBB">Twitter</font></a><br/>
			<br/>
		</div>
		<div class="privacy">2021 &nbsp;All rights reserved <br />
          <!-- Do not remove -->Website by <a href="https://diliberg.net" title="Giovanni Di Liberto">Giovanni Di Liberto</a><!-- end --></div>
		  <!-- Do not remove -->Original design by <a href="http://www.libdesigner.com/2012/08/24/free-animal-skin-and-fur-textures-for-your-projects/" title="Animal Fur Textures">Animal Fur Textures</a><!-- end --><br/>
      </article>
    </div>
  </div>
</footer>
</div>
</body>
</html>
